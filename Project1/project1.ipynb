{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train_input: torch.Size([1000, 2, 14, 14])\n",
      "Size of train_target: torch.Size([1000])\n",
      "Size of train_classes: torch.Size([1000, 2])\n",
      "Size of test_input: torch.Size([1000, 2, 14, 14])\n",
      "Size of test_target: torch.Size([1000])\n",
      "Size of test_classes: torch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "# We import 1000 pairs of digits for the training and the testing inputs, targets and classes\n",
    "number_of_pairs = 1000 \n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets( \n",
    "    number_of_pairs)\n",
    "\n",
    "# Quick verification of the sizes:\n",
    "print('Size of train_input:', train_input.size())\n",
    "print('Size of train_target:', test_target.size())\n",
    "print('Size of train_classes:', test_classes.size())\n",
    "print('Size of test_input:', test_input.size())\n",
    "print('Size of test_target:', test_target.size())\n",
    "print('Size of test_classes:', test_classes.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, nb_hidden=200, initial_layers=2, final_layers=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(initial_layers, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, final_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with Weight Sharing\n",
    "\n",
    "#### We define the same class wether we use auxiliary loss or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightSharing(nn.Module):\n",
    "    def __init__(self, auxiliary_loss = False):\n",
    "        super().__init__()\n",
    "        self.sharedConvNet = ConvNet(initial_layers=1, final_layers=10)\n",
    "        self.auxiliary_loss = auxiliary_loss\n",
    "\n",
    "        self.fc1 = nn.Linear(20,100)\n",
    "        self.fc2 = nn.Linear(100,20)\n",
    "        self.fc3 = nn.Linear(20,2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        image1 = x.narrow(1,0,1)\n",
    "        image2 = x.narrow(1,1,1)\n",
    "\n",
    "        output1 = self.sharedConvNet(image1)\n",
    "        output2 = self.sharedConvNet(image2)\n",
    "        outputCat = torch.cat((output1, output2), 1)\n",
    "\n",
    "        outputCat = F.relu(self.fc1(outputCat))\n",
    "        outputCat = F.relu(self.fc2(outputCat))\n",
    "        outputCat = self.fc3(outputCat)\n",
    "\n",
    "        \n",
    "        if self.auxiliary_loss:\n",
    "            return outputCat, output1, output2\n",
    "        else:\n",
    "            return outputCat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and number of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size, nb_epochs = 50, printAccLoss = False, auxiliary_loss = False, alpha = 0.3, beta = 0.5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    eta = 1e-1\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            if auxiliary_loss:\n",
    "                trainTargetImage1 = (train_classes.narrow(1,0,1)).squeeze()\n",
    "                trainTargetImage2 = (train_classes.narrow(1,1,1)).squeeze()\n",
    "\n",
    "                outputCat, output1, output2 = model(train_input.narrow(0, b, mini_batch_size))\n",
    "                lossCat = criterion(outputCat, train_target.narrow(0, b, mini_batch_size))\n",
    "                loss1 = criterion(output1, trainTargetImage1.narrow(0, b, mini_batch_size))\n",
    "                loss2 = criterion(output2, trainTargetImage2.narrow(0, b, mini_batch_size))\n",
    "\n",
    "                loss = alpha*loss1 + alpha*loss2 + beta*lossCat\n",
    "\n",
    "            else:\n",
    "                output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "                loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "\n",
    "            acc_loss = acc_loss + loss.item()\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= eta * p.grad\n",
    "\n",
    "        if printAccLoss:\n",
    "            print(e, acc_loss)\n",
    "\n",
    "def compute_nb_errors(model, input, target, mini_batch_size, auxiliary_loss = False):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        if auxiliary_loss:\n",
    "            outputCat, _, _ = model(input.narrow(0, b, mini_batch_size))\n",
    "            _, predicted_classes = outputCat.max(1)\n",
    "            for k in range(mini_batch_size):\n",
    "                if target[b + k] != predicted_classes[k]:\n",
    "                    nb_errors = nb_errors + 1\n",
    "        else:\n",
    "            output = model(input.narrow(0, b, mini_batch_size))\n",
    "            _, predicted_classes = output.max(1)\n",
    "            for k in range(mini_batch_size):\n",
    "                if target[b + k] != predicted_classes[k]:\n",
    "                    nb_errors = nb_errors + 1\n",
    "\n",
    "\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "mini_batch_size = 50\n",
    "number_of_runs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error Net 44.50% 445/1000\n",
      "Time for model: 0.0019998550415039062, time for training: 4.278506517410278\n",
      "test error Net 55.20% 552/1000\n",
      "Time for model: 0.0020008087158203125, time for training: 4.29086446762085\n",
      "test error Net 44.70% 447/1000\n",
      "Time for model: 0.0020017623901367188, time for training: 4.339862823486328\n",
      "test error Net 44.10% 441/1000\n",
      "Time for model: 0.001998424530029297, time for training: 4.524110794067383\n",
      "test error Net 43.10% 431/1000\n",
      "Time for model: 0.0020003318786621094, time for training: 4.432950496673584\n",
      "test error Net 56.70% 567/1000\n",
      "Time for model: 0.0010001659393310547, time for training: 4.378861904144287\n",
      "test error Net 42.70% 427/1000\n",
      "Time for model: 0.0020008087158203125, time for training: 4.3442223072052\n",
      "test error Net 44.90% 449/1000\n",
      "Time for model: 0.0019998550415039062, time for training: 4.294865369796753\n",
      "test error Net 45.10% 451/1000\n",
      "Time for model: 0.0019998550415039062, time for training: 4.459066867828369\n",
      "test error Net 53.50% 535/1000\n",
      "Time for model: 0.0009992122650146484, time for training: 4.269865274429321\n"
     ]
    }
   ],
   "source": [
    "for k in range(number_of_runs):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(number_of_pairs)\n",
    "    startTime = time.time()\n",
    "    model = ConvNet()\n",
    "    midTime = time.time()\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "    endTime = time.time()\n",
    "    nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "    print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0), nb_test_errors, test_input.size(0)))\n",
    "    print('Time for model:', str(midTime-startTime) + ', time for training:', endTime-midTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with Weight Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error Net 54.90% 549/1000\n",
      "Time for model: 0.001999378204345703, time for training: 9.065340995788574\n",
      "test error Net 56.80% 568/1000\n",
      "Time for model: 0.002000570297241211, time for training: 9.872064590454102\n",
      "test error Net 42.20% 422/1000\n",
      "Time for model: 0.002000093460083008, time for training: 9.534501314163208\n",
      "test error Net 44.40% 444/1000\n",
      "Time for model: 0.0019989013671875, time for training: 10.395581007003784\n",
      "test error Net 56.50% 565/1000\n",
      "Time for model: 0.001999378204345703, time for training: 9.296208143234253\n",
      "test error Net 47.50% 475/1000\n",
      "Time for model: 0.0020003318786621094, time for training: 9.911978006362915\n",
      "test error Net 55.10% 551/1000\n",
      "Time for model: 0.003000974655151367, time for training: 8.804882287979126\n",
      "test error Net 56.30% 563/1000\n",
      "Time for model: 0.002000570297241211, time for training: 9.042134046554565\n",
      "test error Net 53.10% 531/1000\n",
      "Time for model: 0.002000093460083008, time for training: 9.699244260787964\n",
      "test error Net 46.70% 467/1000\n",
      "Time for model: 0.0009429454803466797, time for training: 9.241259336471558\n"
     ]
    }
   ],
   "source": [
    "for k in range(number_of_runs):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(number_of_pairs)\n",
    "    startTime = time.time()\n",
    "    model = WeightSharing()\n",
    "    midTime = time.time()\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "    endTime = time.time()\n",
    "    nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "    print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0), nb_test_errors, test_input.size(0)))\n",
    "    print('Time for model:', str(midTime-startTime) + ', time for training:', endTime-midTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with Weight Sharing and Auxiliary Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error Net 52.90% 529/1000\n",
      "Time for model: 0.0020008087158203125, time for training: 8.667993307113647\n",
      "test error Net 53.70% 537/1000\n",
      "Time for model: 0.00299835205078125, time for training: 10.951169967651367\n",
      "test error Net 54.70% 547/1000\n",
      "Time for model: 0.002000093460083008, time for training: 11.293402194976807\n",
      "test error Net 57.00% 570/1000\n",
      "Time for model: 0.0030007362365722656, time for training: 10.639906883239746\n",
      "test error Net 54.70% 547/1000\n",
      "Time for model: 0.003000020980834961, time for training: 9.984194040298462\n",
      "test error Net 60.50% 605/1000\n",
      "Time for model: 0.003000974655151367, time for training: 10.346497058868408\n",
      "test error Net 53.10% 531/1000\n",
      "Time for model: 0.0009999275207519531, time for training: 9.057891845703125\n",
      "test error Net 54.20% 542/1000\n",
      "Time for model: 0.0020012855529785156, time for training: 9.096790313720703\n",
      "test error Net 55.90% 559/1000\n",
      "Time for model: 0.003000020980834961, time for training: 9.236965417861938\n",
      "test error Net 54.10% 541/1000\n",
      "Time for model: 0.002000093460083008, time for training: 8.854721069335938\n"
     ]
    }
   ],
   "source": [
    "for k in range(number_of_runs):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(number_of_pairs)\n",
    "    startTime = time.time()\n",
    "    model = WeightSharing(auxiliary_loss=True)\n",
    "    midTime = time.time()\n",
    "    train_model(model, train_input, train_target, mini_batch_size, auxiliary_loss=True)\n",
    "    endTime = time.time()\n",
    "    nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size, auxiliary_loss=True)\n",
    "    print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0), nb_test_errors, test_input.size(0)))\n",
    "    print('Time for model:', str(midTime-startTime) + ', time for training:', endTime-midTime)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e885cd74143ad494932267455ab53278514454996393c47fe6c2589217b9edf3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
